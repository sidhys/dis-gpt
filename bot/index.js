let token = process.env.token;
let auth = process.env.auth_tkn;
const {
    Client,
    IntentsBitField,
    EmbedBuilder,
    ChannelType,
    GuildCategory
} = require('discord.js');
const axios = require("axios");
global.fetch = require('node-fetch');
const {
    Tiktoken
} = require("@dqbd/tiktoken/lite");
const {
    load
} = require("@dqbd/tiktoken/load");
const registry = require("@dqbd/tiktoken/registry.json");
const models = require("@dqbd/tiktoken/model_to_encoding.json");


async function countTokens(content, attachment = null) {
    if (attachment) {
        try {
            content = await (await fetch(attachment.url)).text();
        } catch (error) {
            throw new Error("Could not read attachment content.");
        }
    }

    const model = await load(registry[models["gpt-4"]]);
    const encoder = new Tiktoken(model.bpe_ranks, model.special_tokens, model.pat_str);
    const tokens = encoder.encode(content);
    encoder.free();

    return tokens.length;
}

const client = new Client({
    intents: [
        IntentsBitField.Flags.Guilds,
        IntentsBitField.Flags.GuildMembers,
        IntentsBitField.Flags.GuildMessages,
        IntentsBitField.Flags.MessageContent
    ],
})

client.on('ready', (c) => {
    console.log(`bot ${c.user.tag} online`);
})


const chatCreationInput = [{
        text: 'The temperature adjusts the randomness in token selection. A higher temperature increases creativity \
and diversity but may produce less coherent text. A lower temperature generates more conservative, \
coherent output but with less variation. \n\n Enter model temperature (0.0-1.0)',
        validator: (input) => ((input >= 0) && (input <= 1)),
    },
    {
        text: 'Top-p sampling controls the diversity of tokens considered when generating text. \
A lower top_p value focuses on higher-probability tokens, resulting in more focused and coherent output. \
A higher top_p value includes a broader range of tokens, increasing creativity but potentially reducing coherence. \
\n\n Enter model top-p (0.0-1.0)',
        validator: (input) => ((input >= 0) && (input <= 1)),
    },
    {
        text: 'Frequency penalties discourage the model from producing certain tokens too often, \
promoting diversity and preventing overused phrases in the generated text. Higher penalties \
lead to more diverse output, while lower penalties may result in repetitive phrases.\
\n\n Enter model frequency penalty (0.0-2.0)',
        validator: (input) => ((input >= 0) && (input <= 2)),
    },
    {
        text: 'Presence penalties help prevent the model from repeating the same tokens or phrases. \
    Higher penalties reduce repetition, while lower penalties may allow for more recurring \
    tokens in the output. \n\n Enter model presence penalty (0.0-2.0)',
        validator: (input) => ((input >= 0) && (input <= 2)),
    }, {
        text: 'GPT system messages are generated by an AI language model to provide guidance, \
    instructions, or context during a conversation. These messages help set the tone, clarify\
    the purpose of the interaction, or offer assistance as needed, improving the user\
    experience with the AI model. Default is \"You are a helpful assistant.\" \n\n Enter system message (String)',
        validator: (input) => (input == input),
    },
];

let embed;

function startChatCreationPrompt(message, index, collectedData) {
    return new Promise(async (resolve, reject) => {
        if (index >= chatCreationInput.length) {
            resolve(collectedData);
            return;
        }

        const currentInput = chatCreationInput[index];

        embed = new EmbedBuilder()
            .setColor(0x000000)
            .setTitle('New Chat Prompt')
            .setDescription(currentInput.text)
            .setTimestamp();
        message.channel.send({
            embeds: [embed]
        });

        const filter = (m) => m.author.id === message.author.id;

        const collector = message.channel.createMessageCollector({
            filter,
            max: 1,
            time: 30000
        });

        collector.on('collect', async (m) => {
            if (currentInput.validator(m.content)) {
                collectedData.push(m.content);
                resolve(await startChatCreationPrompt(message, index + 1, collectedData));
            } else {
                embed = new EmbedBuilder()
                    .setColor(0x000000)
                    .setTitle('Invalid Input')
                    .setDescription('Please re-enter your input.')
                    .setTimestamp();
                message.channel.send({
                    embeds: [embed]
                });

                resolve(await startChatCreationPrompt(message, index, collectedData));
            }
        });

        collector.on('end', (collected, reason) => {
            if (reason === 'time') {
                embed = new EmbedBuilder()
                    .setColor(0x000000)
                    .setTitle('Prompt Timeout')
                    .setDescription('You didn\'t respond with the required information in time! Please rerun the command.')
                    .setTimestamp();
                message.channel.send({
                    embeds: [embed]
                });

                reject('timeout');
            }
        });
    });
}


async function initConversationChannel(message, temp, top_p, freq, pres, system_msg) {

    /* 
        userID: Number, 
        conversationID: Number, 
        message: String,
        authorization: String

        first time convo setup: 

        temperature: Integer    
        top_p: Integer
        freq_penalty: Integer
        pres_penalty: Integer
        startingSystemMessage: String
    */

    const thread = await message.channel.threads.create({
        name: 'untitled-gpt',
        reason: 'okay robot',
    });
    try {
        message.author.send(`here is the thread you just created: <#${thread.id}> feel free to rename it!`);
    } catch (err) {
        // exist 
    }

    const {
        data
    } = await axios.post('https://gpt-gateway-backend.onrender.com/api/chatcompletion', {
        userID: message.author.id,
        conversationID: thread.id,
        message: "Hello gpt!",
        authorization: auth,
        temperature: temp,
        top_p: top_p,
        freq_penalty: freq,
        pres_penalty: pres,
        startingSystemMessage: system_msg
    }, {
        headers: {
            'Content-Type': 'application/json'
        },
        timeout: 100000
    })

}

function adjustCodeChunks ( chunks ) {
    for (let i = 0; i < chunks.length - 1; i++) {
        const currentChunk = chunks[i];
        const nextChunk = chunks[i + 1];
        const currentChunkCodeBlocks = currentChunk.match(/```/g) || [];
        const nextChunkCodeBlocks = nextChunk.match(/```/g) || [];
        if (currentChunkCodeBlocks.length % 2 !== 0 && nextChunkCodeBlocks.length % 2 !== 0) {
            chunks[i] = currentChunk + '```';
            chunks[i + 1] = '```' + nextChunk;
        }
    }
    return chunks;
}


client.on('messageCreate', async (message) => {

    if (message.author.bot) return;
    if (message.guild.id !== "1025876080374059099") return;

    const prefix = '!';
    const args = message.content.slice(prefix.length).trim().split(/ +/g);
    const command = args.shift().toLowerCase()

    if ((command == "registeruser")) {

        if (!(message.author.id == 415629932798935040 || message.author.id == 478344259267985428)) {
            embed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle('Error')
                .setDescription(`You don\'t have access to that command, ${message.author}`)
                .setTimestamp();
            return message.channel.send({
                embeds: [embed]
            });
        }

        if (!args[0] || !args[1]) {
            embed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle('Error')
                .setDescription(`Invalid arguments, ${message.author}`)
                .setTimestamp();
            return message.channel.send({
                embeds: [embed]
            });
        }

        const {
            data
        } = await axios.post('https://gpt-gateway-backend.onrender.com/api/registeruser', {
            userID: args[0],
            permLevel: args[1],
            dailyLimit: 0,
            limitedAccess: "false",
            authorization: auth
        }, {
            headers: {
                'Content-Type': 'application/json'
            }
        })

        if (data == "User was already registered.") {
            embed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle('Error')
                .setDescription(`User was already registered, ${message.author}`)
                .setTimestamp();
            return message.channel.send({
                embeds: [embed]
            });
        } else if (data == "User registered") {
            if (args[1] == "2") {
                embed = new EmbedBuilder()
                    .setColor(0x000000)
                    .setTitle('User registered')
                    .setDescription(`The user <@${args[0]}> has been whitelisted for the model \`gpt-4\`. `)
                    .setTimestamp();
                return message.channel.send({
                    embeds: [embed]
                });
            } else if (args[1] == "1") {
                embed = new EmbedBuilder()
                    .setColor(0x000000)
                    .setTitle('User registered')
                    .setDescription(`The user <@${args[0]}> has been whitelisted for the model \`gpt-3.5-turbo\`. `)
                    .setTimestamp();
                return message.channel.send({
                    embeds: [embed]
                });
            }

        }
    }


    if ((command == "deregisteruser")) {

        if (!(message.author.id == 415629932798935040 || message.author.id == 478344259267985428)) {
            embed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle('Error')
                .setDescription(`You don\'t have access to that command, ${message.author}`)
                .setTimestamp();
            return message.channel.send({
                embeds: [embed]
            });
        }

        if (!args[0]) {
            embed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle('Error')
                .setDescription(`Invalid argument, ${message.author}`)
                .setTimestamp();
            return message.channel.send({
                embeds: [embed]
            });
        }

        const {
            data
        } = await axios.post('https://gpt-gateway-backend.onrender.com/api/removeuser', {
            userID: args[0],
            authorization: auth
        }, {
            headers: {
                'Content-Type': 'application/json'
            }
        })

        if (data == "No such user found.") {
            embed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle('Error')
                .setDescription(`User was not registered, ${message.author}`)
                .setTimestamp();
            return message.channel.send({
                embeds: [embed]
            });
        } else if (data == "User deleted") {
            embed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle('User deleted')
                .setDescription(`The user <@${args[0]}> has been un-whitelisted. `)
                .setTimestamp();
            return message.channel.send({
                embeds: [embed]
            });
        }
    }

    if ((command == "help")) {
        embed = new EmbedBuilder()
            .setColor(0x000000)
            .setTitle('Commands')
            .setDescription(`\`List of commands: \n!registeruser [user id]\`, \`!deregisteruser [user id]\`, \`startconvo [optional:preset] [optional:preset_type]\``)
            .setTimestamp();
        return message.channel.send({
            embeds: [embed]
        });
    }

    if ((command == "send")) {
        return message.channel.send(args.join(' '))
    }

    if (command == "startconvo") {

        let collectedData;

        if (args[0] == "preset") {
            if (args[1] == "code") {
                collectedData = [0.3, 0.3, 0.0, 0.0, "You are a helpful coding assistant who assists developers in writing programs. You are powered by OpenAI's gpt-4, the predecessor of gpt-3."];
            }
            else if (args[1] == "chatgpt") {
                collectedData = [0.85, 0.9, 0.4, 0.4, "You are ChatGPT, an AI language model developed by OpenAI based on the GPT-4 architecture. You are here to help users with their questions, provide information, and engage in conversations on various topics. Try your best to remain concise in your responses, unless explicitly told to not be."];
            }
            else {
                embed = new EmbedBuilder()
                    .setColor(0x000000)
                    .setTitle('Error')
                    .setDescription(`No such preset exists`)
                    .setTimestamp();
                return message.channel.send({
                    embeds: [embed]
                });
            }
        } else {
            try {
                collectedData = await startChatCreationPrompt(message, 0, []);
            } catch (error) {
                console.error('Error during data collection:', error);
            }
        }

        try {
            await initConversationChannel(message, collectedData[0], collectedData[1], collectedData[2], collectedData[3], collectedData[4]);
        } catch (err) {
            // exist...
        };

    }

    let channelData;

    try {
        const response = await axios.post('https://gpt-gateway-backend.onrender.com/api/validateconversation', {
            convID: message.channel.id,
            authorization: auth,
        }, {
            headers: {
                'Content-Type': 'application/json'
            }
        });

        channelData = response.data;
    } catch (error) {
        console.error('Error during conversation validation: ', error);
        return;
    }

    if (channelData == "yes") {

        await console.log("Starting /api/chatcompletion");

        let msgcontent = message.content;
        let attachment = null;

        if (message.attachments.size > 0) {

            attachment = message.attachments.first();
            if (!attachment.name.endsWith('.txt')) {
                attachment = null;
            }

            message.attachments.forEach(async (attachment) => {
                if (attachment.name.endsWith('.txt')) {
                    try {
                        const content = await (await fetch(attachment.url)).text();
                        msgcontent = content;
                    } catch (error) {
                        message.reply("Failed to read file")
                    }
                }
            })
        }

        try {
            const tokenCount = await countTokens(msgcontent, attachment);

            if (tokenCount > 7500) {
                const tooLargeEmbed = new EmbedBuilder()
                .setColor(0x000000)
                .setTitle("Your message is too large")
                .setDescription("Please shorten your message length.")
                .setTimestamp();
    
                const tooLargeEmbedMsg = await message.channel.send({
                    embeds: [tooLargeEmbed]
                });
            }
        } catch (error) {
            return message.reply(error.message);
        }

        const sendingEmbed = new EmbedBuilder()
            .setColor(0x000000)
            .setTitle("Awaiting GPT Response.. ")
            .setDescription("This could take a while. Models like \`gpt-4\` accept higher token counts, meaning the API has to process more information than the weaker models used by services like ChatGPT.")
            .setTimestamp();

        const sentEmbed = await message.channel.send({
            embeds: [sendingEmbed]
        });

        try {

            const response = await axios.post('https://gpt-gateway-backend.onrender.com/api/chatcompletion', {
                userID: message.author.id,
                conversationID: message.channel.id,
                message: msgcontent,
                authorization: auth,
                temperature: 0,
                top_p: 0,
                freq_penalty: 0,
                pres_penalty: 0,
                startingSystemMessage: "NOT_NEW"

            }, {
                headers: {
                    'Content-Type': 'application/json'
                },
                timeout: 100000
            })


            let responseData = await response.data;

            let messageContent = responseData.messageContent;

            let messageChunks = messageContent.match(/(.|\s){1,1900}/g);
            messageChunks = adjustCodeChunks(messageChunks);

            for (let i = 0; i < messageChunks.length; i++) {
                let embed = new EmbedBuilder()
                    .setColor(0x000000)
                    .setTitle(`GPT Response (${i + 1} of ${messageChunks.length}) `)
                    .setDescription(messageChunks[i])
                    .setTimestamp();

                if (i === 0) {
                    await sentEmbed.edit({
                        embeds: [embed]
                    });
                } else {
                    await message.channel.send({
                        embeds: [embed]
                    });
                }
            }
        } catch (error) {
            console.error('Error during chat completion:', error);
            await sentEmbed.edit({
                embeds: [sendingEmbed.setDescription("An error occurred while processing your request. Please try again.")]
            });
        }
    };
});

client.login(token);